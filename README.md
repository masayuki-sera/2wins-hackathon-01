# 2WINS AI Hackathon #1 手法解説

本リポジトリは、間取り図画像から部屋名を予測するハッカソンに参加した際のソリューションを公開したものです。  
**Public Score: 1.00 / Private Score: 1.00** を達成しました。

## コンペ元ページ
[https://github.com/2WINS-Inc/ai-hackathon-01-low-res-ocr](https://github.com/2WINS-Inc/ai-hackathon-01-low-res-ocr)

## 手法概要

- **前処理**: テスト画像に対して、EDSRモデルによる超解像度処理を実施し高画質化
- **文字認識**: 高画質化した画像にGoogle Cloud Vision APIを用いてOCR処理を実施、ラベル名を直接抽出
- **画像分類モデル**: OCRでラベルを抽出できなかった画像に対して、EfficientNet-B0とResNet50のアンサンブルによる画像分類を適用しラベルを推定
- **後処理**: OCR結果と画像認識モデル結果を組み合わせたルールベースによる最終ラベル決定

## 工夫点・特徴

### 超解像度処理
- OCR精度を向上させるため、超解像度処理を行った
- 超解像度モデルはtrainデータの低画質画像と高画質画像で訓練し、testデータで推論することで、testデータの各画像に対する高画質画像を作成
### OCR処理
- 高精度なモデルである Google Cloud Vision API を使用
- 超解像度処理後のtestデータに対してOCR処理を施すことで、文字の認識精度が上がった
- 同一画像内に文字が複数含まれる場合、中心に近いものを抽出することで精度が上がった
- 中心に文字があるが正確に抽出できない場合、外側に抽出できる文字があったとしてもラベルを不明とし、画像認識モデルに任せる処理をした
### CNNモデルのアンサンブル
- EfficientNet-B0とResNet50を使用
- 5-foldでvalidationデータでの精度を確認しつつ、アンサンブルすることで汎化性能向上
- early-stoppingを使用し、5回連続でvalidationデータのlossが向上しなかった場合、訓練を中止した
- 5-foldでアンサンブルしたEfficientNet-B0とResNet50をアンサンブルすることで、精度が向上した
- 合計10モデルのアンサンブルということになる
### OCR→画像分類モデルのパイプライン
- OCR処理は文字を文字として認識して抽出するので、抽出できたものに関しては精度が限りなく高い
- OCRをベースのモデルとし、OCRで抽出できなかった画像に対して、画像分類モデルで推論し、ラベル抽出成功率を最大化